## Reference
Minku, Leandro L., and Xin Yao. "Software effort estimation as a multiobjective learning problem." ACM Transactions on Software Engineering and Methodology (TOSEM) 22.4 (2013): 35.

## Introduction
The paper views Software Effort Estimation(SEE) as a Multiobjective learning problem, by using a MOEA (multiobjective evolutionary algorithm). It mentions that both under and overestimation of effort for SEE can cause losses and human effort is commonly used for it. Instead, SEE can use automated effort estimators. it is very difficult to further test, evaluate and enhance very promising estimation approaches that are based on the UML models constructed in the early state of requirements analysis. The paper looks at a new type of learning method, ensamblems of learning machines. Ensembles are sets of learners trained to perform the same task and combined with the aim of improving predictive performance. Ensembles are promising for SEE but need to be tuned for thus task. Minku and Yao [2013] showed that combining the power of ensembles to local learning through the use of bagging ensembles of regression trees outperforms several other learning machines for SEE in terms of Mean Absolute Error (MAE). Even with all this research on the topic, the ensemble method is not fully automated and needs manual inspection for creation of the ensembles. 
Much of the SEE work involves empirical evaluation of models and several different measures of performance can be used for that. Different measures can behave differently and it is highly unlikely that there is a “single, simple-touse, universal goodness-of-tit kind of metric" 

## Aim of the paper
- Find relationships between different performance measures for SEE
- Can we use different performance measures as a source of diversity to create SEE ensembles?
- Is it possible to ceate a model to emphasize of particular performace measures if so?

## Machine learning for SEE
Recently, effort estimators based on machine learning approaches such asMulti- Layer Perceptrons (MLPs), Radial Basis Function networks (RBFs) and Regression Trees (RTs). Another type of approaches that has been recently attracting the attention of the SEE community are ensembles of learning machines. But, this approach has high implementation complexity and is not fully automated. there is a trade-off between accuracy and diversity of base models. So, if we focus only on improving their accuracy, they are likely to lack diversity, reducing the accuracy of the ensemble as a whole.

## MOEAS
MOEAs are population-based optimisation algorithms that evolve sets of candidate solutions by optimising two or more possibly conflicting objectives. Candidate solutions are generated/evolved through evolutionary operators such as crossover and mutation in rounds called generations. The evolutionary process is frequently guided by the concept of dominance. Dominance is a multiobjective roblems and can be easily generalized for maximization. They chose HaD-MOEA(harmonic distance MOEA) as the algorithm.

### ALGORITHM: HaD-MOEA
```
Input: population size α, number of generations G.
Output: Pg.
1 Initialize initial population P1 = {x1, x2, . . . , xα};
2 for g ← 1 to G do
  3 Generate offspring population Qg from Pg with size α;
  4 Combine parent and offspring population Rg = Pg ∪ Qg;
  5 Sort all solutions of Rg to get all nondominated fronts F = fast nondominated sort(Rg),
  where F = (F1, F2, . . .);
  6 Set Pg+1 = {} and i = 1;
  7 while the population size |Pg+1| + |Fi | < N do
  8 Add the ith nondominated front Fi to Pg+1;
  9 i = i + 1;
  10 end
  11 Combine Fi and Pg+1 to a temporary vector T;
  12 Calculated the harmonic crowding distance of individuals of Fi in T;
  13 Sort Fi according to the crowding distance;
  14 Set T = {};
  15 Fill Pg+1 with the first α − |Pg+1| elements of Fi ;
16 end
```

Metrics can be used as fitness functions in search based software engineering, being able to guide the force behind the search for optimal or near optimal solutions in such a way to automate software engineering tasks. In the paper, they innovatively formulate the problem of creating SEE models as a multiobjective learning problem. The metrics to be optimized:

- Mean Magnitude of the Relative Error(MMRE)
- Percentage of estimations within 25% of the actual values(PRED)
- Logarithmic Standard Deviation(LSD)

MMRE and LSD are objectives to be minimized, whereas PRED(25) is to be maximized. the objective values are calculated using a set of projects with known effort which will be referred to as the training set. When evaluating the results of the approaches, the performance measures are calculated over the test set. The models generated by MOEA in this paper are Multi-Layer Perceptrons (MLPs) 

The solutions produced by HaD-MOEA are innovatively used for SEE in two ways in this paper:

- The first one is a Pareto ensemble composed of the best-fit Pareto solutions. These solutions are the ones with the best train performance considering each objective separately. So, the ensemble will be composed of the Pareto solution with the best train LSD, best train MMRE and best train PRED(25). This avoids the need for a software manager to decide on a certain measure to be emphasized.
- The second way to use the solutions produced by HaD-MOEA is to use each best fit Pareto solution by itself.

## Data Set
based on five data sets from the PRedictOr Models In Software Engineering Software (PROMISE) Repository [Shirabad and Menzies 2005] and eight data sets based on the International Software Benchmarking Standards Group (ISBSG) Repository [ISBSG 2011] Release 10.

## Relationship between performance measures
All the three objectives have to be considered at the same time to determine whether a solution is (non)dominated.
Some of the conclusions:

- as MMRE is improved (reduced), LSD tends to get worse (increased).
- solutions with similar PRED(25) frequently present different LSD.
- average LSD by itself is not necessarily a good performance measure and may be affected by a few estimations containing extreme values
- MMRE, PRED(25) and LSD behave differently, indicating that they may be useful for creating SEE ensembles.

Ensemble based on concurrent optimization of performance measures: shows that the use of MOEA for considering several performance measures at the same time is successful in generating SEE ensembles. So, it is worth considering the creation of SEE models as a multiobjective problem and the Pareto ensemble can be used when none of the performance measures is to be emphasized over the others.

The paper showed that MOEA-evolved MLPs are able to achieve competitive results in comparison to other approaches in the literature. The Pareto ensemble usually obtained comparatively good results in terms of all measures but LSD. 

## Conclusion
Conclusion for each aim:

- For aim 1:  They show that LSD and MMRE are performance measures with somewhat opposite behaviour. Moreover, models with similar LSD/MMRE are likely to present different PRED(25) and vice-versa.
- For aim 2:They show that indeed a MOEA can be used to create models by explicitly considering different performance measures at the same time.
- For aim 3: we show that MOEAs are also flexible, allowing the software manager to choose models that emphasize certain performance measures over the others, if they desires to do so.

More experimentation with MOEAs and different model creations can be an improvement to solidify the paper's claims. Also, effect of data on its own on this process is unknown.


